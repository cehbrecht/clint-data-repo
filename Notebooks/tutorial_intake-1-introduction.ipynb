{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Intake I - find, browse and access `intake-esm` collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```{admonition} Overview\n",
    ":class: dropdown\n",
    "\n",
    "![Level](https://img.shields.io/badge/Level-Introductory-green.svg)\n",
    "\n",
    "\n",
    "üéØ **objectives**: Learn how to use `intake` to find, browse and access `intake-esm` ESM-collections\n",
    "\n",
    "‚åõ **time_estimation**: \"30min\"\n",
    "\n",
    "‚òëÔ∏è **requirements**: `intake_esm.__version__ >= 2023.4.*`, at least 10GB memory.\n",
    "\n",
    "¬© **contributors**: k204210\n",
    "\n",
    "‚öñ **license**:\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Agenda\n",
    ":class: tip\n",
    "\n",
    "In this part, you learn\n",
    "\n",
    "1. [Motivation of intake-esm](#motivation)\n",
    "1. [Features of intake and intake-esm](#features)\n",
    "1. [Browse through catalogs](#browse)\n",
    "1. [Data access via intake-esm](#dataaccess)\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"motivation\"></a>\n",
    "\n",
    "We follow here the guidance presented by `intake-esm` on its [repository](https://intake-esm.readthedocs.io/en/latest/user-guide/cmip6-tutorial.html). \n",
    "\n",
    "## Motivation of intake-esm\n",
    "\n",
    "> Simulations of the Earth‚Äôs climate and weather generate huge amounts of data. These data are often persisted on different storages in a variety of formats (netCDF, zarr, etc...). Finding, investigating, loading these data assets into compute-ready data containers costs time and effort. The data user needs to know what data sets are available, the attributes describing each data set, before loading a specific data set and analyzing it.\n",
    "\n",
    "> `Intake-esm` addresses these issues by providing necessary functionality for **searching, discovering, data access and data loading**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For intake users, many data preparation tasks **are no longer necessary**. They do not need to know:\n",
    "\n",
    "- üåç where data is saved\n",
    "- ü™ß how data is saved\n",
    "- üì§  how data should be loaded\n",
    "\n",
    "but still can search, discover, access and load data of a project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"features\"></a>\n",
    "\n",
    "## Features of intake and intake-esm\n",
    "\n",
    "Intake is a generic **cataloging system** for listing data sources. As a plugin, `intake-esm` is built on top of `intake`, `pandas`, and `xarray` and configures `intake` such that it is able to also **load and process** ESM data.\n",
    "\n",
    "- display catalogs as clearly structured tables üìÑ inside jupyter notebooks for easy investigation\n",
    "- browse üîç through the catalog and select your data without\n",
    "    - being next to the data (e.g. logged in on dkrz's luv)\n",
    "    - knowing the project's data reference syntax i.e. the storage tree hierarchy and path and file name templates\n",
    "- open climate data in an analysis ready dictionary of `xarray` datasets üéÅ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All required information for searching, accessing and loading the catalog's data is configured within the catalogs:\n",
    "\n",
    "- üåç where data is saved\n",
    "    * users can browse data without knowing the data storage platform including e.g. the root path of the project and the directory syntax\n",
    "    * data of different platforms (cloud or disk) can be combined in one catalog\n",
    "    * on mid term, intake catalogs can be **a single point of access**\n",
    "- ü™ß how data is saved\n",
    "    * users can work with a *xarray* dataset representation of the data no matter whether it is saved in **grb, netcdf or zarr** format.\n",
    "    * catalogs can contain more information an therefore more search facets than obvious from names and pathes of the data.\n",
    "- üì§  how data should be loaded\n",
    "    * users work with an **aggregated** *xarray* dataset representation which merges files/assets perfectly fitted to the project's data model design.\n",
    "    * with *xarray* and the underlying *dask* library, data which are **larger than the RAM** can be loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we load a CMIP6 catalog which contains all data from the pool on DKRZ's mistral disk storage.\n",
    "CMIP6 is the 6th phase of the Coupled Model Intercomparison Project and builds the data base used in the IPCC AR6.\n",
    "The CMIP6 catalog contains all data that is published or replicated at the ESGF node at DKRZ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"terminology\"></a>\n",
    "\n",
    "## Terminology: **Catalog**, **Catalog file** and **Collection**\n",
    "\n",
    "We align our wording with `intake`'s [*glossary*](https://intake.readthedocs.io/en/latest/glossary.html) which is still evolving. The names overlap with other definitions, making it difficult to keep track. Here we try to give an overview of the hierarchy of catalog terms:\n",
    "\n",
    "- a **top level catalog file** üìã is the **main** catalog of an institution which will be opened first. It contains other project [*catalogs*](#catalog)  üìñ üìñ üìñ. Such catalogs can be assigned an [*intake driver*](#intakedriver) which is used to open and load the catalog within the top level catalog file. Technically, a catalog file üìã is <a class=\"anchor\" id=\"catalogfile\"></a>\n",
    "    - is a `.yaml` file\n",
    "    - can be opened with `open_catalog`, e.g.:\n",
    "```python\n",
    "    intake.open_catalog([\"https://dkrz.de/s/intake\"])\n",
    "```\n",
    "- **intake driver**s also named **plugin**s are specified for [*catalogs*](#catalog) becaues they load specific data sets. There are [many driver](https://intake.readthedocs.io/en/latest/plugin-directory.html) libraries for intake. <a class=\"anchor\" id=\"intakedriver\"></a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- a **catalog** üìñ (or collection) is defined by two parts: <a class=\"anchor\" id=\"catalog\"></a>\n",
    "    - a **description** of a group of data sets. It describes how to *load* **assets** of the data set(s) with the specified [driver](#intakedriver). This group forms an entity. E.g., all CMIP6 data sets can be collected in a catalog. <a class=\"anchor\" id=\"description\"></a>\n",
    "        - an **asset** is most often a file. <a class=\"anchor\" id=\"asset\"></a>\n",
    "    - a **collection** of all [assets](#asset) of the data set(s).   <a class=\"anchor\" id=\"collection\"></a>\n",
    "        - the collection can be included in the catalog or separately saved in a **data base** üóÇ. In the latter case, the catalog references the data base, e.g.:\n",
    "```json\n",
    "  \"catalog_file\": \"/mnt/lustre02/work/ik1017/Catalogs/dkrz_cmip6_disk.csv.gz\"\n",
    "```\n",
    "\n",
    "```{note}\n",
    "The term *collection* is often used synonymically for [catalog](#catalog).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- a *intake-esm* **catalog**  üìñ consists of a `.json` file (the **description**) and the underlying data base. The data base is either provided within the `.json` file or as a `.csv.gz` formatted list. \n",
    "\n",
    "The intake-esm catalog can be opened with intake-esm's function `intake.open_esm_datastore()` where the `.json` part is the argument, e.g:\n",
    "\n",
    "```python\n",
    "intake.open_esm_datastore(\"https://gitlab.dkrz.de/data-infrastructure-services/intake-esm/-/raw/master/esm-collections/cloud-access/dkrz_cmip6_disk.json\")\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note that intake_esm is imported with `import intake` as a plugin\n",
    "import intake\n",
    "#to find out the version of intake-esm, you can do:\n",
    "import intake_esm\n",
    "intake_esm.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"browse\"></a>\n",
    "\n",
    "## Open and browse through catalogs\n",
    "\n",
    "intake (not intake-esm) **opens** catalog-files in `yaml` format. These contain information about additonal sources: other catalogs/collections which will be loaded with specific *plugins*/*drivers*. The command is `open_catalog`.\n",
    "\n",
    "<mark> You only need to remember one URL as the *single point of access* for DKRZ's intake catalogs: The DKRZ top level catalog can be accessed via dkrz.de/s/intake . Intake will only follow this *redirect* if a specific parser is activated. This can be done by providing the url in a list.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dkrz_catalog=intake.open_catalog([\"https://dkrz.de/s/intake\"])\n",
    "#dkrz_catalog=intake.open_catalog([\"/pool/data/Catalogs/dkrz_catalog.yaml\"])\n",
    "#\n",
    "#only for the web page we need to take the original link:\n",
    "dkrz_catalog=intake.open_catalog([\"https://gitlab.dkrz.de/data-infrastructure-services/intake-esm/-/raw/intake2022/esm-collections/cloud-access/dkrz_catalog.yaml\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c6=dkrz_catalog[\"dkrz_cmip6_disk\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Right now, two versions of the top level catalog file exist: One for accessing the catalog via [cloud](https://gitlab.dkrz.de/data-infrastructure-services/intake-esm/-/raw/master/esm-collections/cloud_access/dkrz_catalog.yaml), one for via [disk](https://gitlab.dkrz.de/data-infrastructure-services/intake-esm/-/raw/master/esm-collections/disk_access/dkrz_catalog.yaml). They however contain **the same content**.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look into the catalog with `print` and `list`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the time, many collections have been created. `dkrz_catalog` is a **main** catalog prepared to keep an overview of all other collections. `list` shows all sub **project catalogs** which are available at DKRZ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dkrz_catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these catalogs are **intake-esm** catalogs. You can find this information via the `_entries` attribute. The line `plugin: ['esm_datastore']\n",
    "` refers to **intake-esm**'s function `open_esm_datastore()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dkrz_catalog._entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DKRZ ESM-Collections follow a name template:\n",
    "\n",
    "`dkrz_${project}_${store}[_${auxiliary_catalog}]`\n",
    "\n",
    "where\n",
    "\n",
    "- **project** can be one of the *model intercomparison project*, e.g. `cmip6`, `cmip5`, `cordex`, `era5` or `mpi-ge`.\n",
    "- **store** is the data store and can be one of:\n",
    "    - `disk`: DKRZ holds a lot of data on a consortial disk space on the file system of the High Performance Computer (HPC) where it is accessible for every HPC user. Working next to the data on the file system will be the fastest way possible.\n",
    "    - `cloud`: A small subset is transferred into DKRZ's cloud in order to test the performance. swift is DKRZ's cloud storage.\n",
    "    - `archive`: A lot of data exists in the band archive of DKRZ. Before it can be accessed, it has to be retrieved. Therefore, catalogs for `hsm` are limited in functionality but still convenient for data browsing.\n",
    "- **auxiliary_catalog** can be *grid*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why that convention?**:\n",
    "\n",
    "- **dkrz**: Assume you work with internation collections. Than it may become important that you know from where the data comes, e.g. if only pathes on a local file system are given as the locations of the data.\n",
    "- **project**: Project's data standards differ from each other so that different catalog attributes are required to identify a single asset in a project data base.\n",
    "- **store**: Intake-esm cannot load data from all stores. Before data from the archive can be accessed, it has to be retrieved. Therefore, the opening function is not working for catalog merged for all stores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best practice for naming catalogs**:\n",
    "\n",
    "- Use small letters for all values\n",
    "- Do **NOT** use `_` as a separator in values\n",
    "- Do not repeat values of other attributes (\"dkrz_dkrz-dyamond\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could directly start to work with **two intake catalog** at the same time.\n",
    "\n",
    "Let's have a look into a master catalog of [Pangeo](https://pangeo.io/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pangeo=intake.open_catalog(\"https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/master.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pangeo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(pangeo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While DKRZ's master catalog has one sublevel, Pangeo's is a nested one. We can access another `yaml` catalog which is also a **parent** catalog by simply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pangeo.climate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pangeo's ESM collections are one level deeper in the catalog tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(pangeo.climate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `intake-esm` catalogs\n",
    "\n",
    "We now look into a catalog which is opened by the plugin `intake-esm`. \n",
    "\n",
    "> An ESM (Earth System Model) collection file is a `JSON` file that conforms to the ESM Collection Specification. When provided a link/path to an esm collection file, intake-esm establishes a link to a database (`CSV` file) that contains data assets locations and associated metadata (i.e., which experiment, model, the come from).\n",
    "\n",
    "Since the data base of the CMIP6 ESM Collection is about 100MB in compressed format, it takes up to a minute to load the catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "The project catalogs contain only valid and current project data. They are constantly updated.\n",
    "\n",
    "If your work is based on a catalog and a subset of the data from it, be sure to save that subset so you can later compare your database to the most current catalog.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esm_col=dkrz_catalog.dkrz_cmip6_disk\n",
    "print(esm_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`intake-esm` gives us an overview over the content of the ESM collection. The ESM collection is a data base described by specific attributes which are technically columns. Each project data standard is the basis for the columns and used to parse information given by the path and file names.\n",
    "\n",
    "The pure display of `esm_col` shows us the number of unique values in each column. Since each `uri` refers to one file, we can conclude that the DKRZ-CMIP6 ESM Collection contains **6.1 Mio Files** in 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data base is loaded into an underlying `panda`s dataframe which we can access with `esm_col.df`. `esm_col.df.head()` displays the first rows of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esm_col.df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find out details about `esm_col` with the object's attributes. `esm_col.esmcol_data` contains all information given in the `JSON` file. We can also focus on some specific attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict(esm_col.esmcat)[\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"What is this catalog about? \\n\" + dict(esm_col.esmcat)[\"description\"])\n",
    "#\n",
    "print(\"The link to the data base: \"+ dict(esm_col.esmcat)[\"catalog_file\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced: To find out how many datasets are available, we can use pandas functions (drop columns that are irrelevant for a dataset, drop the duplicates, keep one):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = esm_col.df.drop(['uri','time_range'],axis=1).drop_duplicates(keep=\"first\")\n",
    "print(len(cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pieplot(gbyelem) :\n",
    "    #groupby, sort and select the ten largest\n",
    "    global c6\n",
    "    size = c6.df.groupby([gbyelem]).size().sort_values(ascending=False)\n",
    "    size10 = size.nlargest(10)\n",
    "    #Sum all others as 10th entry\n",
    "    size10[9] = sum(size[9:])\n",
    "    size10.rename(index={size10.index.values[9]:'all other'},inplace=True)\n",
    "    #return a pie plot\n",
    "    return size10.plot.pie(figsize=(18,8),ylabel='',autopct='%.2f', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pieplot(\"source_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Browse through the data of the ESM collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will browse the collection technically by setting values the **column names** of the underlying table. Per default, the catalog was loaded with all cmip6 attributes/columns that define the CMIP6 data standard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esm_col.df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are configured in the top level catalog so you <mark> do not need to open the catalog to see the columns </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dkrz_catalog._entries[\"dkrz_cmip6_disk\"]._open_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, we want to set more than one attribute for a search. Therefore, we define a query `dict`ionary and use the `search` function of the `esm_col` object. In the following case, we look for temperature at surface in monthly resolution for 3 different experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = dict(\n",
    "    variable_id=\"tas\",\n",
    "    table_id=\"Amon\",\n",
    "    experiment_id=[\"piControl\", \"historical\", \"ssp370\"])\n",
    "# piControl = pre-industrial control, simulation to represent a stable climate from 1850 for >100 years.\n",
    "# historical = historical Simulation, 1850-2014\n",
    "# ssp370 = Shared Socioeconomic Pathways (SSPs) are scenarios of projected socioeconomic global changes. Simulation covers 2015-2100\n",
    "cat = esm_col.search(**query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also use *Wildcards*. For example, in order to find out which ESMs of the institution *MPI-M* have produced data for our subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.search(source_id=\"MPI-ES*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find out which models have submitted data for at least one of them by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat.unique()[\"source_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we instead look for the models that have submitted data for ALL experiments, we use the `require_all_on` keyword argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat = esm_col.search(require_all_on=[\"source_id\"], **query)\n",
    "cat.unique()[\"source_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that only the combination of a `variable_id` and a `table_id` is unique in CMIP6. If you search for `tas` in all tables, you will find many entries more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = dict(\n",
    "    variable_id=\"tas\",\n",
    "#    table_id=\"Amon\",\n",
    "    experiment_id=[\"piControl\", \"historical\", \"ssp370\"])\n",
    "cat = esm_col.search(**query)\n",
    "cat.unique()[\"table_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful when you search for specific time slices. Each frequency is connected with a individual name template for the filename. If the data is yearly, you have YYYY-YYYY whereas you have YYYYMM-YYYYMM for monthly data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to load more columns\n",
    "\n",
    "Intake allows to load only a subset of the columns that is inside the **intake-esm** catalog. Since the memory usage of **intake-esm** is high, the default columns are only a subset from all possible columns. Sometimes, other columns are of interest:\n",
    "\n",
    "If you work remotely away from the data, you can use the **opendap_url**'s to access the subset of interest for all files published at DKRZ. The *opendap_url* is an *additional* column that can also be loaded.\n",
    "\n",
    "We can define 3 different column name types for the usage of intake catalogs:\n",
    "\n",
    "1. **Default** attributes which are loaded from the main catalog and which can be seen via `_entries[CATNAME]._open_args`.\n",
    "2. **Overall** attributes or **template** attributes which should be defined for **ALL** catalogs at DKRZ (exceptions excluded). At DKRZ, we use the newly defined **Cataloonie** scheme template which can be found via `dkrz_catalog.metadata[\"parameters\"][\"cataloonie_columns\"]`. With these template attributes, there may be redundancy in the columns. They exist to simplify merging catalogs across projects.\n",
    "3. **Additional** attributes which are not necessary to identify a single asset but helpful for users. You can find these via\n",
    "\n",
    "`dkrz_catalog.metadata[\"parameters\"][\"additional_PROJECT_columns\"]`\n",
    "\n",
    "So, for CMIP6 there are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dkrz_catalog.metadata[\"parameters\"][\"additional_cmip6_disk_columns\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "You may find *variable_id*s in the catalog which are not obvious or abbrevations for a clear variable name. In that cases you would need additional information like a *long_name* of the variable. For CMIP6, we provided the catalog with this `long_name` so you could add it as a column.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this is the instruction how to open the catalog with additional columns:\n",
    "\n",
    "1. create a combination of all your required columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=dkrz_catalog._entries[\"dkrz_cmip6_disk\"]._open_args[\"read_csv_kwargs\"][\"usecols\"]+[\"opendap_url\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. open the **dkrz_cmip6_disk** catalog with the `csv_kwargs` keyword argument in this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#esm_col=dkrz_catalog.dkrz_cmip6_disk(read_csv_kwargs=dict(usecols=cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ‚≠ê The customization of catalog columns allows highest flexibility for intake users. \n",
    "- ‚≠ê In theory, we could add many more columns with additional information because ot all have to be loaded from the data base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{warning}\n",
    "The number of columns determines the required memory.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "If you work from remote and also want to access the data remotely, load the *opendap_url* column.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"dataaccess\"></a>\n",
    "\n",
    "## Access and load data of the ESM collection\n",
    "\n",
    "With the power of `xarray`, `intake` can load your subset into a `dict`ionary of datasets. We therefore focus on the data of `MPI-ESM1-2-LR`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#case insensitive?\n",
    "query = dict(\n",
    "    variable_id=\"tas\",\n",
    "    table_id=\"Amon\",\n",
    "    source_id=\"MPI-ESM1-2-LR\",\n",
    "    experiment_id=\"historical\")\n",
    "cat = esm_col.search(**query)\n",
    "cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find out which column intake uses to access the data via the following keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.esmcat.assets.column_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intake-ESM** natively supports the following data formats or access formats (since opendap is not really a file format):\n",
    "\n",
    "- netcdf\n",
    "- opendap\n",
    "- zarr\n",
    "\n",
    "You can also open **grb** data but right now only by specifying xarray's attribute *engine* in the *open* function which is defined in the following. I.e., it does not make a difference if you specify **grb** as format.\n",
    "\n",
    "You can find an example in the *era5* notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function to open data is `to_dataset_dict`. \n",
    "\n",
    "We recommend to set a keyword argument `xarray_open_kwargs` for the chunk size of the variable's data array. Otherwise, `xarray` may choose too large chunks. Most often, your data contains a time dimension so that you could set `xarray_open_kwargs={\"chunks\":{\"time\":1}}`. \n",
    "\n",
    "If your collection contains **zarr** formatted data, you need to add another keyword argument `zarr_kwargs`.\n",
    "\n",
    "**Unfortunately, this has changed in new versions**:\n",
    "\n",
    "    - DEPRICATED The trick is: You can just specify both. Intake knows from the `format` column which *kwargs* should be taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "help(cat.to_dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xr_dict = cat.to_dataset_dict(\n",
    "    #xarray_open_kwargs=\n",
    "    #dict(\n",
    "    #    chunks=dict(\n",
    "    #        time=60\n",
    "    #    ),\n",
    "        #consolidated=True\n",
    "        #decode_times=True,\n",
    "        #use_cftime=True\n",
    "    #)\n",
    ")\n",
    "xr_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Intake` was able to aggregate many files into only one dataset:\n",
    "- The `time_range` column was used to **concat** data along the `time` dimension\n",
    "- The `member_id` column was used to generate a new dimension\n",
    "\n",
    "The underlying `dask` package will only load the data into memory if needed. Note that attributes which disagree from file to file, e.g. *tracking_id*, are excluded from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How **intake-esm** should open and aggregate the assets is configured in the *aggregation_control* part of the description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.esmcat.aggregation_control.aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns can be defined for appending or creating new dimensions. The *options* are keyword arguments for xarray.\n",
    "\n",
    "They **keys** of the dictionary are made with column values defined in the *aggregation_control* of the **intake-esm** catalog. These will determine the **key_template**. The corresponding commands are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cat.esmcat.aggregation_control.groupby_attrs)\n",
    "#\n",
    "print(cat.key_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are only interested in the **first** dataset of the dictionary, we can *pop it out*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xr_dset = xr_dict.popitem()[1]\n",
    "xr_dset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting\n",
    "\n",
    "The variables are collected in **one** dataset. This requires that **the dimensions and coordinates must be the same over all files**. Otherwise, xarray cannot merge these together.\n",
    "\n",
    "For CMIP6, most of the variables collected in one **table_id** should be on the same dimensions and coordinates. Unfortunately, there are exceptions.: \n",
    "\n",
    "- a few variables are requested for *time slices* only. \n",
    "- sometimes models use different dimension names from file to file\n",
    "\n",
    "Using the [preprocessing](https://tutorials.dkrz.de/tutorial_intake-4-preprocessing-derived-vars.html#use-preprocessing-when-opening-assets-and-creating-datasets) keyword argument can help to rename dimensions before merging.\n",
    "\n",
    "For Intake providers: the more information on the dimensions and coordinates provided already in the catalog, the better the aggregation control."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (based on the module python3/2023.01)",
   "language": "python",
   "name": "python3_2023_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "metadata": {
   "execution": {
    "timeout": 60
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
